---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Celena Kim"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: true
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon="false"}
## Github Repo Link

[Celena Kim Repo Link](https://github.com/stat301-2-2024-winter/final-project-2-celenakim)
:::

```{r}
#| echo: false

# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(doMC)

# handle common conflicts
tidymodels_prefer()

# load training data/fits
load(here("results/allies_split.rda"))
load(here("results/lm_fit_recipe3.rda"))
load(here("results/null_fit_recipe1.rda"))

# load pre-processing/feature engineering/recipe
load(here("results/recipe1_kitchen_sink.rda"))
load(here("results/recipe2_kitchen_sink_trees.rda"))
load(here("results/recipe3_interactions.rda"))
load(here("results/recipe4_trasnformed_trees.rda"))
set.seed(301)
```

## Data Cleaning

The data that I chose for my project, `allies`, was derived from gathering data on the psychological analysis of comments under the Jubilee video titled [Are We Allies? Black Americans vs Asian Americans | Middle Ground](https://www.youtube.com/watch?v=pXo2ub_nZFc) found on [YouTube](https://www.youtube.com). After a quick skim of my data set in progress memo 1, I realized that some cleaning needed to be carried out: renaming columns A-P to the correct variable names as they did not get copied over from the original spreadsheet when creating the data set, renaming the LIWC variable names such as "Sixltr" and "posemo" to make more sense to the audience, deleting variables irrelevant to my analysis/variables with missingness, mutating a categorical predictor variable called "comment_length" which categorizes a comment as short, medium, or long, and arranging variable order to be more organized. After these changes were made, my data was then ready for analyses to be performed.


## Assessment Metric
My predictive research question is: What psychological factors lead to a comment receiving more likes on the Jubilee video, "Are We Allies? Black Americans vs Asian Americans | Middle Ground"?

This is a regression problem as I would like to predict a numerical outcome: `likes`, the like count of a comment. The assessment metric I will be using to evaluate the performance of my model will be the **RMSE**. This metric will help me understand how well the models are at predicting......


## Analysis Plan
Data splitting: I will use a proportion of 0.75 to split the data and use stratified sampling.

Resampling: I will also apply V-fold cross validation to the training dataset using 10 folds and 5 repeats 

Models: simple linear, null, elastic, knn, random forest, boosted tree

Recipes: Kitchen sink recipe (kitchen_sink_recipe), Kitchen sink recipe with one hot (kitchen_sink_recipe_trees), Recipe 2 with interaction terms (allies_recipe2)


## Two Model Types
1. lm model with allies_recipe2
2. null model with allies_recipe2


## Fit Success
```{r}
#| echo: false


lm_fit_recipe3 |> 
  collect_metrics() |> 
  mutate(model = "lm") |> 
  bind_rows(null_fit_recipe1 |> 
              collect_metrics() |>  
              mutate(model = "null")) |> 
  select(-.config) |> 
  knitr::kable()
```



## Summarize Progress & Next Steps
Now that I have some recipes and fits going, I want to start creating other model types and tuning such models. I would also like to play around with different folds/repeats combinations and potentially tweak my current recipes. 