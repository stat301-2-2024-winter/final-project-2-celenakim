---
title: "Executive Summary: Predicting the Length of Comments on the Jubilee Middle Ground video 'Are We Allies? Black Americans vs Asian Americans'"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Celena Kim"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
---

::: {.callout-tip icon="false"}
## Github Repo Link

[Celena Kim Repo Link](https://github.com/stat301-2-2024-winter/final-project-2-celenakim)
:::


### Introduction
The purpose of this report was to predict how long a comment on the Jubilee video "Are We Allies? Black Americans vs Asian Americans | Middle Ground" found on YouTube is, between a category of either short or long. This was achieved by carrying out a classification prediction problem, with the length of the comment as the target variable, and the predictor variables being numerical scores of how much each comment communicates various emotions/categories such as anger, sadness, power, assent, insight, and affiliation, as well as a categorical predictor of whether the comment contains positive emotion or not. An 80-20 training-test split using stratified sampling and repeated V-fold cross-validation was conducted on 11 different models of type null, logistic regression, elastic net, k nearest neighbors, boosted tree, and random forest utilizing 4 different recipes. Finally, the assessment metric used to compare models to ultimately determine the winning model was accuracy.

### Model Results
After building and running my models, I obtained the following results for accuracy:
![](results/tbl_result_accuracy.png) 

As can be seen in the table, my winning model was my random forest model as this model obtained the highest accuracy out of all my models of 0.949. This accuracy value suggests that the model was able to correctly identify whether a comment was short or long with a 94.9% success rate.

### Analysis of the Final Model
After fitting the winning random forest model to my testing data set, I assessed its performance using various assessment metrics.
![](results/winning_accuracy_dt.png)

For the first assessment metric, I obtained a very high accuracy value of 0.993. This suggests that approximately 99.3% of the predictions made by the winning model match the actual lengths of comments in the testing dataset, supporting high performance of the model in predicting the length of comments.
![](results/conf_mat_rf_dt.png)

Next, I created a confusion matrix, which essentially represents of the performance of a classification model, with True Positives & True Negatives (correct predictions) and False Positives & False Negatives (incorrect predictions). According to the confusion matrix above, the winning model correctly predicted the lengths of 3,057 comments in the testing data, and predicted lengths incorrectly for only 23 comments.

![](results/winning_roc_curve.png)
Finally, I plotted the winning model's ROC curve, which represents its overall performance. If the curve was close to the diagonal line, then my modelâ€™s predictions would be unsuccessful and no better than random guessing. However, since the curve is very close to the top left-hand corner, I can conclude that my model is very successful at various thresholds. The area under the ROC curve was also calculated to be 0.999, which is a very high value and suggests that the random forest a model has very high performance in correctly predicting comment lengths.


### Conclusion
Overall, these four assessment metrics support a high level of prediction performance for my winning random forest model a, thus rendering this model to be successful in  its ability to predict whether a comment under the Jubilee video "Are We Allies? Black Americans vs Asian Americans | Middle Ground" would be short or long. Such a prediction model is advantageous in providing a more general understanding of how certain emotions/perceptions influence the level of conversation and discussion that a viewer may be prompted to engage in after viewing a YouTube video such as Jubilee's, allowing for an in-depth analysis of the dynamics of online discourse. By analyzing the emotional and perceptual triggers that prompt users to engage in discussion, we gain an understanding of the underlying factors driving conversation. Such insights are invaluable for content creators such as Jubilee who seek to foster meaningful dialogue and possibly cultivate inclusive online communities. 




